{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-08 15:51:28--  https://www.dropbox.com/s/k23enjvr3fb40o5/corpora.zip?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6027:18::a27d:4812\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/k23enjvr3fb40o5/corpora.zip [following]\n",
      "--2022-05-08 15:51:28--  https://www.dropbox.com/s/raw/k23enjvr3fb40o5/corpora.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com/cd/0/inline/Bk48TLNOH5KO54k7k7m14GpegLieWYnIKYOBq0H7S9EXngO7Nx1-V7ZPYHmejqh45viufQj1yR4B4OgN2zHQm9S4mIgnmxt-bn5A3R0FEWvYMqR9a20G5fpm4OarVedc6yo2ljtQ-7-Tof7gSqXSmDZuH_gPxOqwLc7kt5ei2qG5pQ/file# [following]\n",
      "--2022-05-08 15:51:29--  https://uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com/cd/0/inline/Bk48TLNOH5KO54k7k7m14GpegLieWYnIKYOBq0H7S9EXngO7Nx1-V7ZPYHmejqh45viufQj1yR4B4OgN2zHQm9S4mIgnmxt-bn5A3R0FEWvYMqR9a20G5fpm4OarVedc6yo2ljtQ-7-Tof7gSqXSmDZuH_gPxOqwLc7kt5ei2qG5pQ/file\n",
      "Resolving uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com (uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6027:15::a27d:480f\n",
      "Connecting to uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com (uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/Bk7g3089KgkKCWcMjvTNiF53uVOHjMmVgT2CbXDuV2eKQAwo86gnOgsu72Vlj3zoO73uxgqRuJR-8_J4BxTc2zGyX1I-1_qFZpj-tN1q7opIBzliEkd3a9odiLNR4b5JKm5Zp8NP0UsDUPSaPQDcEr4ejtyKZR150d5onuJv5rQMhXWUS3HnQTomVjmy4II0317kFvyDDyC1gici3ivK0t4fpZNpMrtycWOe0UOj_rULZ-h9IJYwSaIk7-vguiGZjXAeaqKmjkgBkMsUAu4hwt2zdiwZ2tnet3CIwO0WbAEPl4O5GHvUdEPcyQgwks6E5EDIfXEvYNxexMXiYNM3EMLllH-nL-C3JfeY4abc8_M3M3z6rwpTZ-X5u9LweWPRrjEOXYRkNPbIodJLNg6shDlFULiTwLug35st4ZpXnSquWg/file [following]\n",
      "--2022-05-08 15:51:29--  https://uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com/cd/0/inline2/Bk7g3089KgkKCWcMjvTNiF53uVOHjMmVgT2CbXDuV2eKQAwo86gnOgsu72Vlj3zoO73uxgqRuJR-8_J4BxTc2zGyX1I-1_qFZpj-tN1q7opIBzliEkd3a9odiLNR4b5JKm5Zp8NP0UsDUPSaPQDcEr4ejtyKZR150d5onuJv5rQMhXWUS3HnQTomVjmy4II0317kFvyDDyC1gici3ivK0t4fpZNpMrtycWOe0UOj_rULZ-h9IJYwSaIk7-vguiGZjXAeaqKmjkgBkMsUAu4hwt2zdiwZ2tnet3CIwO0WbAEPl4O5GHvUdEPcyQgwks6E5EDIfXEvYNxexMXiYNM3EMLllH-nL-C3JfeY4abc8_M3M3z6rwpTZ-X5u9LweWPRrjEOXYRkNPbIodJLNg6shDlFULiTwLug35st4ZpXnSquWg/file\n",
      "Reusing existing connection to uce7d4aa5f315d9b56b46e73c2da.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2434585 (2.3M) [application/zip]\n",
      "Saving to: ‘corpora.zip’\n",
      "\n",
      "corpora.zip         100%[===================>]   2.32M  11.7MB/s    in 0.2s    \n",
      "\n",
      "2022-05-08 15:51:30 (11.7 MB/s) - ‘corpora.zip’ saved [2434585/2434585]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O corpora.zip https://www.dropbox.com/s/k23enjvr3fb40o5/corpora.zip?dl=0\n",
    "!unzip corpora.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath: str) -> str:\n",
    "    with open(filepath, 'r') as fin:\n",
    "        content = fin.read()\n",
    "    return content\n",
    "\n",
    "anna_karenina = read_file('AnnaKarenina.txt')\n",
    "war_and_peace = read_file('WarAndPeace.txt')\n",
    "war_and_peace_eng = read_file('WarAndPeaceEng.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = f'{anna_karenina}\\n{war_and_peace}'\n",
    "test_text = \"\"\"\n",
    "Утром шестнадцатого апреля доктор Бернар Риэ, выйдя из квартиры, споткнулся на лестничной площадке о дохлую крысу.\n",
    "Как-то не придав этому значения, он отшвырнул ее носком ботинка и спустился по лестнице.\n",
    "Но уже на улице он задал себе вопрос, откуда бы взяться крысе у него под дверью, и он вернулся сообщить об этом происшествии привратнику.\n",
    "Реакция старого привратника мсье Мишеля лишь подчеркнула, сколь необычным был этот случай.\n",
    "Если доктору присутствие в их доме дохлой крысы показалось только странным, то в глазах привратника это был настоящий позор.\n",
    "Впрочем, мсье Мишель занял твердую позицию: в их доме крыс нет.\n",
    "И как ни уверял его доктор, что сам видел крысу на площадке второго этажа, и, по всей видимости, дохлую крысу, мсье Мишель стоял на своем.\n",
    "Раз в доме крыс нет, значит, кто-нибудь подбросил ее нарочно. Короче, кто-то просто подшутил.\n",
    "\"\"\".replace('\\n', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def prepare_text(text: str) -> str:\n",
    "    translation = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translation).lower()\n",
    "    return text\n",
    "\n",
    "train_text = prepare_text(train_text)\n",
    "test_text = prepare_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from typing import Iterable\n",
    "\n",
    "def calculate_sorted_frequency(text: Iterable[str]) -> dict[str, int]:\n",
    "    sorted_frequency = Counter(text).most_common()\n",
    "    return sorted_frequency\n",
    "\n",
    "def get_tokens_sorted_by_frequency(text: Iterable[str]) -> list[str]:\n",
    "    sorted_frequency = calculate_sorted_frequency(text)\n",
    "    tokens_sorted_by_frequency = list(zip(*sorted_frequency))[0]\n",
    "    return tokens_sorted_by_frequency\n",
    "\n",
    "def apply_chars_mapping(text: str, mapping: dict[str, str]):\n",
    "    text = ''.join([mapping[char] for char in text])\n",
    "    return text\n",
    "\n",
    "def encode_text(text: Iterable[str]) -> str:\n",
    "    text_chars = list(set(text))\n",
    "    shuffled_chars = text_chars.copy()\n",
    "    shuffle(shuffled_chars)\n",
    "    mapping = dict(zip(text_chars, shuffled_chars))\n",
    "    encoded_text = apply_chars_mapping(text, mapping)\n",
    "    return encoded_text\n",
    "\n",
    "def decode_text(encoded_text: str, source_text: str):\n",
    "    encoded_tokens = get_tokens_sorted_by_frequency(encoded_text)\n",
    "    source_tokens = get_tokens_sorted_by_frequency(source_text)[:len(encoded_tokens)]\n",
    "    mapping = dict(zip(encoded_tokens, source_tokens))\n",
    "    decoded_text = apply_chars_mapping(encoded_text, mapping)\n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'утром шестнадцатого апреля доктор бернар риэ выйдя из квартиры споткнулся на лестничной площадке о дохлую крысу както не придав этому значения он отшвырнул ее носком ботинка и спустился по лестнице но уже на улице он задал себе вопрос откуда бы взяться крысе у него под дверью и он вернулся сообщить об этом происшествии привратнику реакция старого привратника мсье мишеля лишь подчеркнула сколь необычным был этот случай если доктору присутствие в их доме дохлой крысы показалось только странным то в глазах привратника это был настоящий позор впрочем мсье мишель занял твердую позицию в их доме крыс нет и как ни уверял его доктор что сам видел крысу на площадке второго этажа и по всей видимости дохлую крысу мсье мишель стоял на своем раз в доме крыс нет значит ктонибудь подбросил ее нарочно короче ктото просто подшутил'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'эчджхщейшчпсврсчжожщстдйнищвжычждщзйдпсдщдк щгьлвищкющыгсдчкдьщштжчыпэншищпсщнйшчпкапжлщтнжмсвыйщжщвжянэцщыдьшэщысычжщпйщтдквсгщ чжхэщюпсайпкищжпщжчегьдпэнщййщпжшыжхщзжчкпысщкщштэшчкншищтжщнйшчпкрйщпжщэбйщпсщэнкрйщжпщюсвснщшйзйщгжтджшщжчыэвсщзьщгюичушищыдьшйщэщпйожщтжвщвгйдуцщкщжпщгйдпэншищшжжзмкчущжзщ чжхщтджкшейшчгккщтдкгдсчпкыэщдйсыркищшчсджожщтдкгдсчпкысщхшуйщхкейнищнкеущтжвайдыпэнсщшыжнущпйжзьапьхщзьнщ чжчщшнэаслщйшнкщвжычждэщтдкшэчшчгкйщгщкящвжхйщвжянжлщыдьшьщтжысюснжшущчжнуыжщшчдсппьхщчжщгщонсюсящтдкгдсчпкысщ чжщзьнщпсшчжимклщтжюждщгтджайхщхшуйщхкейнущюспинщчгйдвэцщтжюкркцщгщкящвжхйщыдьшщпйчщкщысыщпкщэгйдинщйожщвжычждщачжщшсхщгквйнщыдьшэщпсщтнжмсвыйщгчжджожщ чсбсщкщтжщгшйлщгквкхжшчкщвжянэцщыдьшэщхшуйщхкейнущшчжинщпсщшгжйхщдсющгщвжхйщыдьшщпйчщюпсакчщычжпкзэвущтжвзджшкнщййщпсджапжщыжджайщычжчжщтджшчжщтжвеэчкн'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = encode_text(test_text)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'меиоп чателскхсео\\nо суиавь кореои ыаилси инж дяйкь нб рдсиения туоерлмвть лс вателнзлой уво–скра о кошвмю риятм рсрео ла уинксд жеопм блсзалнь ол оечдяилмв аа лотроп ыоенлрс н тумтенвть уо вателнха ло мэа лс мвнха ол бсксв таыа доуиот оермкс ыя дбьегть рията м ла\\nо уок кдаигю н ол даилмвть тооы–нег оы жеоп уионтчатеднн уиндиселнрм иасрхнь тесио\\nо уиндиселнрс птга пнчавь внчг уокзаирлмвс тровг лаоыязляп ыяв жеое твмзсй атвн кореоим уинтметедна д нш копа кошвой риятя уорсбсвотг еовгро теислляп ео д \\nвсбсш уиндиселнрс жео ыяв лстеоь–нй уобои дуиозап птга пнчавг бсльв едаикмю уобнхню д нш копа рият лае н рср лн мдаиьв а\\nо кореои зео тсп днкав риятм лс уво–скра деоио\\nо жесэс н уо дтай днкнпотен кошвмю риятм птга пнчавг теоьв лс тдоап исб д копа рият лае блсзне реолнымкг уокыиотнв аа лсиозло роиоза реоео уиотео уокчменв'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text = decode_text(encoded_text, train_text)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.2727272727272727'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy(truth: Iterable[str], prediction: Iterable[str]) -> float:\n",
    "    assert len(truth) == len(prediction)\n",
    "    correctly_predicted = sum(truth[i] == prediction[i] for i in range(len(truth)))\n",
    "    accuracy = correctly_predicted / len(truth)\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(test_text, decoded_text)\n",
    "f'Accuracy: {accuracy}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 9.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 40.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2022.4.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "\u001b[K     |████████████████████████████████| 763 kB 40.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.1.0 nltk-3.7 regex-2022.4.24 tqdm-4.64.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ут', 'тр', 'ро', 'ом', 'м ', ' ш', 'ше', 'ес', 'ст', 'тн']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "\n",
    "def generate_bigrams(text: str) -> list[str]:\n",
    "    bigrams = [''.join(bigram) for bigram in ngrams(text, 2)]\n",
    "    return bigrams\n",
    "\n",
    "test_text_bigrams = generate_bigrams(test_text)\n",
    "test_text_bigrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_with_bigrams(encoded_text: str, train_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Decodes encoded text using bi-grams statistics:\n",
    "        1. Sorts bigrams from both encoded and train texts by frequency.\n",
    "        2. In each iteration, gets an index of an encoded bigram and maps it to the train bigram \n",
    "           with the closest index that has the first character equal to the last character in the decoded sequence\n",
    "    \"\"\"\n",
    "    train_text_bigrams = generate_bigrams(train_text)\n",
    "    encoded_text_bigrams = generate_bigrams(encoded_text)\n",
    "\n",
    "    sorted_train_bigrams = get_tokens_sorted_by_frequency(train_text_bigrams)\n",
    "    sorted_encoded_bigrams = get_tokens_sorted_by_frequency(encoded_text_bigrams)\n",
    "\n",
    "    encoded_bigram = encoded_text[:2]\n",
    "    train_bigram = sorted_train_bigrams[sorted_encoded_bigrams.index(encoded_bigram)]\n",
    "    mapping = {\n",
    "        encoded_bigram: train_bigram \n",
    "    }\n",
    "    used_train_bigrams = {train_bigram}\n",
    "    decoded_text = train_bigram\n",
    "    for i in range(1, len(encoded_text) - 1):\n",
    "        encoded_bigram = encoded_text[i:i+2]\n",
    "        if encoded_bigram in mapping:\n",
    "            decoded_text += mapping[encoded_bigram][1]\n",
    "            continue\n",
    "\n",
    "        possible_train_bigram_index = sorted_encoded_bigrams.index(encoded_bigram)\n",
    "        possible_train_bigram = sorted_train_bigrams[possible_train_bigram_index]\n",
    "        i = 0\n",
    "        while possible_train_bigram[0] != decoded_text[-1]:\n",
    "            if possible_train_bigram_index - i > 0:\n",
    "                left_possible_train_bigram = sorted_train_bigrams[possible_train_bigram_index - i]\n",
    "                if left_possible_train_bigram[0] == decoded_text[-1] and left_possible_train_bigram not in used_train_bigrams:\n",
    "                    possible_train_bigram = left_possible_train_bigram\n",
    "                    break\n",
    "            \n",
    "            if possible_train_bigram_index + i < len(sorted_train_bigrams):\n",
    "                right_possible_train_bigram = sorted_train_bigrams[possible_train_bigram_index + i]\n",
    "                if right_possible_train_bigram[0] == decoded_text[-1] and right_possible_train_bigram not in used_train_bigrams:\n",
    "                    possible_train_bigram = right_possible_train_bigram\n",
    "                    break\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        train_bigram = possible_train_bigram\n",
    "        mapping[encoded_bigram] = train_bigram\n",
    "        used_train_bigrams.add(train_bigram)\n",
    "\n",
    "        decoded_text += train_bigram[1]\n",
    "    return decoded_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'азналадел данята затый этракоро дос быасодичавымньаясь хосиля у – чейск еамаривл дужетважаедрнудниткобойн  т ках моо тм нж итих ре лсхаюачтуулаиныичихывыскиманмтькрласпчлутмрял –18 ль еаж тивл думунмтт — нмар кумуниныашниеи лы нвса аьничевнирсеувшаглюеа т клн хм жатж гдкннбры ялинывнбыск еа яз шеелои аре лаж апезел лезлж исянадусвхдэлопала  исазатж исянадусмругоенувеетраиуебож гатбуйскср крядом ф епекеасееире чу ойтнсамлоулкоро д хж иеазв лечнв яжиколинкобоева т ктуж рмешееьоог ядврт  нндлкеаг тв «нсешииж исянадусмрре тсееимае  пиешаж врдовл абтсаугоенувеетдоашдьсиглнбайн ж вума\\n в яжиколин т кнм нуял мозмул dнблсимжаткоро доюб т maаветяти т кахмаржаедрнуднвз дазатреицерялж твдлкаветклжь ллкобойн  т кахугоенувеетдо   псимар цсмсаднеьв колин т кнм нуаюач еу о нучннтож гииаьеьиманмасабетт рдабтн о ч тж аь  тж г cзль'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_with_bigrams_text = decode_with_bigrams(encoded_text, train_text)\n",
    "decoded_with_bigrams_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_accuracy = calculate_accuracy(test_text, decoded_with_bigrams_text)\n",
    "f'Bigram Accuracy: {bigram_accuracy}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acaad0331f316a70b861142f74b391395b97d22c8d097e900ceac6b955e313c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('adv-ml-hw3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
